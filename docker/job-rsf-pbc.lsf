#BSUB -W 2:00
#BSUB -o /rsrch3/scratch/int_rad_rsch/ipaolucci/logs/pymc-survival
#BSUB -e /rsrch3/scratch/int_rad_rsch/ipaolucci/logs/pymc-survival
#BSUB -cwd /rsrch3/home/int_rad_rsch/ipaolucci/src/pymc-survival/docker
#BSUB -q short
#BSUB -n 5 
#BSUB -M 16
#BSUB -R rusage[mem=16]
#BSUB -u ipaolucci@mdanderson.org
#BSUB -J rsf_pbc 
## explanation of arguments above:
## -W run-time (wall clock) in hour:min  (required)
## -o use this or output (stdout) will be sent via email!
## -e use this or errors (stderr) will be sent via email!
## -cwd set the current working directory.
## -q queue name (required) 
## -n number of processors required (28=entire node)
## -M memory limit in GB (required). 
## -R memory reserved in GB (default/minimum is 1GB).
## -B send email to the user when the job begins (optional).
## -N send email to the user when the job ends (optional).
## -u send email to the specified address (required if -B and -N are used).
##    It is recommended to always include your MD Anderson email address.
## -J arbitrary job name, letters, dashes, underscores only - no spaces!
##
## Memory is specified as GB
##
## This script requests a wallclock of 1 hour, 12 CPUs, and 17G of memory, in the short queue

## To submit:  bsub < example.lsf

## All commands below should be valid linux commands
#

module load singularity/3.7.0

singularity exec \
    --env WORKING_DIRECTORY=/home/pymc/src/examples/experiments \
    --env PYTHONPATH=/home/pymc/src \
    --no-home \
    --bind $HOME/src/pymc-survival:/home/pymc/src \
    modelling_pymc4-jupyter-latest.sif \
    /bin/bash -c " \
        export AESARA_FLAGS="base_compiledir=/tmp/.aesara"
        python /home/pymc/src/examples/experiments/run_experiment.py rsf rsf_pbc data/pbc --runs 100 --jobs 5 --n-iter 25 \
    "


